import json
from datetime import datetime
from typing import Dict, Any, List, Optional
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
from config import OPENAI_API_KEY, DEFAULT_MAX_TOKENS
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–∑–¥–∞–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á.")
from .token_counter import get_token_count, calculate_cost
import asyncio

import logging

logger = logging.getLogger('telegram_bot')

async def send_message_to_openai(
    model: str, 
    input_text: str, 
    messages: List[Dict[str, str]] = None,
    system_instruction: Optional[str] = None,
    max_tokens: Optional[int] = None,
    stream: bool = False
) -> Dict[str, Any]:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ OpenAI API –∏ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"""

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    client = AsyncOpenAI(api_key=OPENAI_API_KEY, timeout=30.0)

    # –ï—Å–ª–∏ max_tokens –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    if max_tokens is None:
        max_tokens = DEFAULT_MAX_TOKENS
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
    if messages is None:
        messages = []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    api_messages = []
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏
    if system_instruction:
        api_messages.append({
            "role": "system",
            "content": system_instruction
        })
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    for message in messages:
        api_messages.append(message)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏–∏
    if not messages or messages[-1]["role"] != "user" or messages[-1]["content"] != input_text:
        api_messages.append({"role": "user", "content": input_text})
    
    try:
        start_time = datetime.now()
        logger.info(f"üîÑ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API —Å –º–æ–¥–µ–ª—å—é {model} –≤ {start_time.strftime('%H:%M:%S')}")
        logger.info(f"üßæ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–ø—Ä–æ—Å–∞: {api_messages[-1]['content'][:50]}...")
        logger.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(api_messages)}")
        if system_instruction:
            logger.info(f"üîÆ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–ø—Ä–æ–º–ø—Ç): {system_instruction[:50]}...")

        # –û—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
        from .token_counter import get_token_count
        estimated_input_tokens = 0
        for msg in api_messages:
            estimated_input_tokens += get_token_count(msg["content"], model)
        logger.info(f"üìä –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ: {estimated_input_tokens}")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ API
        try:
            logger.info(f"‚è±Ô∏è –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API")
            response = await client.chat.completions.create(
                model=model,
                messages=api_messages,
                max_tokens=max_tokens,
                stream=stream
            )
            end_time = datetime.now()
            elapsed = (end_time - start_time).total_seconds()
            logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API –∑–∞ {elapsed:.2f} —Å–µ–∫.")
        except Exception as api_error:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {str(api_error)}")
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–ª–æ–∫–∞ try/except

        if stream:
            # –î–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º —Å—Ç—Ä–∏–º
            return {
                "success": True,
                "stream": response,
                "input_tokens": estimated_input_tokens
            }
        else:
            # –î–ª—è –æ–±—ã—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
            output_text = response.choices[0].message.content
            output_tokens = response.usage.completion_tokens
            output_cost = calculate_cost(output_tokens, model, is_input=False)
            
            return {
                "success": True,
                "output_text": output_text,
                "output_tokens": output_tokens,
                "output_cost": output_cost,
                "input_tokens": estimated_input_tokens
            }
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return {
            "success": False,
            "error": str(e)
        }