import json
from typing import Dict, Any, List, Optional
from openai import AsyncOpenAI
from dotenv import load_dotenv
load_dotenv()  # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
from config import OPENAI_API_KEY
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª .env —Å–æ–∑–¥–∞–Ω –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π API –∫–ª—é—á.")
from .token_counter import get_token_count, calculate_cost
import asyncio

async def send_message_to_openai(
    model: str, 
    input_text: str, 
    messages: List[Dict[str, str]] = None,
    system_instruction: Optional[str] = None
) -> Dict[str, Any]:
    """–û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ OpenAI API –∏ –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç"""
    import logging

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –±—ã—Ç—å —É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏, —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã
    client = AsyncOpenAI(api_key=OPENAI_API_KEY, timeout=30.0)
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é
    if messages is None:
        messages = []
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ –Ω–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    api_messages = []
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –¥–ª—è –º–æ–¥–µ–ª–∏
    if system_instruction:
        api_messages.append({
            "role": "system",
            "content": system_instruction
        })
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    for message in messages:
        api_messages.append(message)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏–∏
    if not messages or messages[-1]["role"] != "user" or messages[-1]["content"] != input_text:
        api_messages.append({"role": "user", "content": input_text})
    
    try:
        logging.info(f"üîÑ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API —Å –º–æ–¥–µ–ª—å—é {model}")
        logging.info(f"üßæ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–ø—Ä–æ—Å–∞: {api_messages[-1]['content'][:50]}...")
        logging.info(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏: {len(api_messages)}")

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ API
        try:
            logging.info(f"‚è±Ô∏è –ù–∞—á–∞–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenAI API")
            response = await client.chat.completions.create(
                model=model,
                messages=api_messages,
                max_tokens=4000
            )
            logging.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç OpenAI API")
        except Exception as api_error:
            logging.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞ –∫ API: {str(api_error)}")
            raise  # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–ª–æ–∫–∞ try/except
        
        # –ü–æ–ª—É—á–∏–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        output_text = response.choices[0].message.content
        
        # –°—á–∏—Ç–∞–µ–º —Ç–æ–∫–µ–Ω—ã
        input_tokens = response.usage.prompt_tokens
        output_tokens = response.usage.completion_tokens
        
        # –°—á–∏—Ç–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
        input_cost = calculate_cost(input_tokens, model, True)
        output_cost = calculate_cost(output_tokens, model, False)
        
        return {
            "success": True,
            "output_text": output_text,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "input_cost": input_cost,
            "output_cost": output_cost,
            "total_cost": input_cost + output_cost,
        }
    
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI API: {str(e)}")
        import traceback
        logging.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
        
        return {
            "success": False,
            "error": str(e),
            "input_tokens": get_token_count(input_text, model),
            "output_tokens": 0,
            "input_cost": calculate_cost(get_token_count(input_text, model), model, True),
            "output_cost": 0,
            "total_cost": calculate_cost(get_token_count(input_text, model), model, True),
        }